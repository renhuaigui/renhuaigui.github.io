<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>面试基础题 | Huaigui</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、操作系统1.进程有那几种状态，状态转换图，及转换的事件进程包括三种状态： 就绪、运行和阻塞。

就绪—&amp;gt;执行：对就绪状态的进程，当进程调度程序按一种选择策略选中一个就绪的进程，为之分配处理机后，改进成的状态由就绪转换成运行。
执行—&amp;gt;: 正在执行的进程因发生某等待事件而无法执行，则进程有执行变为阻塞，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源得不到满足时">
<meta property="og:type" content="article">
<meta property="og:title" content="面试基础题">
<meta property="og:url" content="http://yoursite.com/2016/09/13/面试基础题/index.html">
<meta property="og:site_name" content="Huaigui">
<meta property="og:description" content="一、操作系统1.进程有那几种状态，状态转换图，及转换的事件进程包括三种状态： 就绪、运行和阻塞。

就绪—&amp;gt;执行：对就绪状态的进程，当进程调度程序按一种选择策略选中一个就绪的进程，为之分配处理机后，改进成的状态由就绪转换成运行。
执行—&amp;gt;: 正在执行的进程因发生某等待事件而无法执行，则进程有执行变为阻塞，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源得不到满足时">
<meta property="og:updated_time" content="2016-09-27T02:15:35.724Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="面试基础题">
<meta name="twitter:description" content="一、操作系统1.进程有那几种状态，状态转换图，及转换的事件进程包括三种状态： 就绪、运行和阻塞。

就绪—&amp;gt;执行：对就绪状态的进程，当进程调度程序按一种选择策略选中一个就绪的进程，为之分配处理机后，改进成的状态由就绪转换成运行。
执行—&amp;gt;: 正在执行的进程因发生某等待事件而无法执行，则进程有执行变为阻塞，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源得不到满足时">
  
    <link rel="alternate" href="/atom.xml" title="Huaigui" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Huaigui</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">成功只有一步之遥</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-面试基础题" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/13/面试基础题/" class="article-date">
  <time datetime="2016-09-13T11:31:23.000Z" itemprop="datePublished">2016-09-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      面试基础题
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、操作系统"><a href="#一、操作系统" class="headerlink" title="一、操作系统"></a>一、操作系统</h1><h4 id="1-进程有那几种状态，状态转换图，及转换的事件"><a href="#1-进程有那几种状态，状态转换图，及转换的事件" class="headerlink" title="1.进程有那几种状态，状态转换图，及转换的事件"></a>1.进程有那几种状态，状态转换图，及转换的事件</h4><p>进程包括三种状态： 就绪、运行和阻塞。</p>
<ul>
<li>就绪—&gt;执行：对就绪状态的进程，当进程调度程序按一种选择策略选中一个就绪的进程，为之分配处理机后，改进成的状态由就绪转换成运行。</li>
<li>执行—&gt;: 正在执行的进程因发生某等待事件而无法执行，则进程有执行变为阻塞，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源得不到满足时变成等待资源状态，进程运行中出现了故障变成等待干预状态等等</li>
<li>阻塞—&gt;就绪： 处于阻塞状态的进程，在其等待的事件已经发生，资源得到满足或者错误处理完毕时，处于等待状态的进程并不马上转入执行状态，而是先转入到就绪状态，然后由操作系统调度程序在适当的时候调度</li>
<li>执行—&gt;就绪： 在在执行的进程，因时间片用完而被暂时停止执行，或在采用抢先式调度算法的系统中，有更高优先级的进程要执行而被迫让出处理机时，该进程便由执行状态转变为就绪状态。</li>
</ul>
<h4 id="2-进程与线程的区别和联系。"><a href="#2-进程与线程的区别和联系。" class="headerlink" title="2. 进程与线程的区别和联系。"></a>2. 进程与线程的区别和联系。</h4><ol>
<li>定义<br>1）进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.<br>2）线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源</li>
<li>关系<br>一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.<br>相对进程而言，线程是一个更加接近于执行体的概念，它可以与同进程中的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。</li>
<li>区别<br>进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。<br>a.简而言之,一个程序至少有一个进程,一个进程至少有一个线程.<br>b.线程的划分尺度小于进程，使得多线程程序的并发性高。<br>c.另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。<br>d.线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。<br>e.从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。</li>
</ol>
<h4 id="3-进程通信的几种方式。"><a href="#3-进程通信的几种方式。" class="headerlink" title="3. 进程通信的几种方式。"></a>3. 进程通信的几种方式。</h4><ol>
<li>含义<br>进程是转入内存并准备执行的程序,每个程序都有私有的虚拟地址空间,由代码,数据以及它可利用的系统资源(如文件,管道)组成.多进程/多线程是windows操作系统的一个基本特征.Linux系统一般都统称为进程.<br>由于不同的进程运行在各自不同的内存空间中,其中一个进程对于变量的修改另一方是无法感知的,因此,进程之间的消息传递不能通过变量或其他数据结构直接进行,只能通过进程间通信来完成. 进程间通信是指不同进程间进行数据共享和数据交换 .</li>
<li>进程通信的分类<br>根据进程通信时信息量大小的不同,可以将进程通信划分为两大类型:控制信息的通信( 低级通信 )和大批数据信息的通信( 高级通信 ).<br>低级通信主要用于进程之间的同步,互斥,终止和挂起等等控制信息的传递.<br>高级通信主要用于进程间数据块数据的交换和共享,常见的高级通信有管道,消息队列,共享内存等.</li>
<li>进程通信的方式<br>1)文件和记录锁定<br>为避免两个进程间同时要求访问同一资源而引起访问和操作的混乱, 在进程对共享资源进行访问前必须对其锁定 , 该进程访问完后再释放 . 这是为共享资源提供的互斥性保障.<br>2)管道<br>管道是一种半双工的通信方式,数据只能单向流动,而且 只能在具有亲缘关系的进程间使用 . 进程的亲缘关系一般指的是父子关系.管道一般用于两个不同进程之间的通信.当一个进程创建了一个管道,并调用fork创建自己的一个子进程后,父进程关闭读管道端,子进程关闭写管道端,这样提供了两个进程之间数据流动的一种方式.<br>3)有名管道<br>有名管道也是一种半双工的通信方式,但是它 允许无亲缘关系进程间的通信 .<br>4)FIFO<br>FIFO是一种先进先出的队列.它类似于一个管道,只允许数据的单向流动.每个FIFO都有一个名字,允许你不相关的进程访问同一个FIFO,因此也成为命名管.<br>5)信号量<br>信号量是一个计数器,可以用来控制多个线程对共享资源的访问.,它 不是用于交换大批数据 , 而用于多线程之间的同步 . 它常作为一种锁机制 , 防止某进程在访问资源时其它进程也访问该资源 .因此,主要作为进程间以及同一个进程内不同线程之间的同步手段.<br>6)信号<br>信号是一种比较复杂的通信方式,用于通知接收进程某个事件已经发生.<br>7)消息队列<br>消息队列是消息的链表,存放在内核中并由消息队列标识符标识. 消息队列克服了信号传递信息少 , 管道只能承载无格式字节流以及缓冲区大小受限等特点 . 消息队列是不同进程之间可实现共享资源的一种机制, 允许不同进程将格式化的数据流以消息队列形式发送给任意进程 .对消息队列具有操作权限的进程都可以使用msget完成对消息队列的操作控制.通过使用消息类型,进程可以按任何顺序读信息,或为消息安排优先级顺序.<br>8)共享内存<br>共享内存就是映射一段能被其他进程所访问的内存,这段共享内存由一个进程创建,但多个进程都可以访问.共享内存是最快的IPC(进程间通信)方式,它是针对其它进程间通信方式运行效率低而专门设计的.它 往往与其他通信机制 , 如信号量 , 配合使用 , 来实现进程间的同步与通信 .<br>9)套接字(socket)<br>套接口也是一种进程间通信机制,与其他通信机制不同的是,它可用于不同进程及其间进程的通信.</li>
</ol>
<h4 id="4-线程同步几种方式。-一定要会写生产者、消费者问题，完全消化理解"><a href="#4-线程同步几种方式。-一定要会写生产者、消费者问题，完全消化理解" class="headerlink" title="4. 线程同步几种方式。(一定要会写生产者、消费者问题，完全消化理解)"></a>4. 线程同步几种方式。(一定要会写生产者、消费者问题，完全消化理解)</h4><ol>
<li>互斥锁和读写锁：提供对临界资源的保护，当多线程试图访问临界资源时，都必须通过获取锁的方式来访问临界资源。（临界资源：是被多线程共享的资源）当读写线程获取锁的频率差别不大时，一般采用互斥锁，如果读线程访问临界资源的频率大于写线程，这个时候采用读写锁较为合适，读写锁允许多个读线程同时访问临界资源，读写线程必须互斥访问临界资源。读写锁的实现采用了互斥锁，所以在读写次数差不多的情况下采用读写锁性能没有直接采用互斥锁来的高。</li>
<li>条件变量：提供线程之间的一种通知机制，当某一条件满足时，线程A可以通知阻塞在条件变量上的线程B，B所期望的条件已经满足，可以解除在条件变量上的阻塞操作，继续做其他事情。</li>
<li>信号量：提供对临界资源的安全分配。如果存在多份临界资源，在多个线程争抢临界资源的情况下，向线程提供安全分配临界资源的方法。如果临界资源的数量为1，将退化为锁。</li>
<li>令牌：一种高级的线程同步的方法。它既提供锁的安全访问临界资源的功能，又利用了条件变量使得线程争夺临界资源时是有序的。</li>
<li><h5 id="生产者消费者"><a href="#生产者消费者" class="headerlink" title="生产者消费者"></a>生产者消费者</h5>一组生产者进程和一组消费者进程共享一个初始为空、大小为n的缓冲区，只有缓冲区没满时，生产者才能把消息放入到缓冲区，否则必须等待；只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或者一个消费者从中取出消息。<br>1) 关系分析。生产者和消费者对缓冲区互斥访问是互斥关系，同时生产者和消费者又是一个相互协作的关系，只有生产者生产之后，消费者才能消费，他们也是同步关系。<br>2) 整理思路。这里比较简单，只有生产者和消费者两个进程，正好是这两个进程存在着互斥关系和同步关系。那么需要解决的是互斥和同步PV操作的位置。<br>3) 信号量设置。信号量mutex作为互斥信号量，它用于控制互斥访问缓冲池，互斥信号量初值为1；信号量full用于记录当前缓冲池中“满”缓冲区数，初值为0。信号量empty 用于记录当前缓冲池中“空”缓冲区数，初值为n。<br><strong>生产者消费者代码</strong> 使用ＰＶ操作<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">semaphore mutex=1; //临界区互斥信号量</div><div class="line">semaphore empty=n;  //空闲缓冲区</div><div class="line">semaphore full=0;  //缓冲区初始化为空</div><div class="line">producer () &#123; //生产者进程</div><div class="line">    while(1)&#123;</div><div class="line">        produce an item in nextp;  //生产数据</div><div class="line">        P(empty);  //获取空缓冲区单元</div><div class="line">        P(mutex);  //进入临界区.</div><div class="line">        add nextp to buffer;  //将数据放入缓冲区</div><div class="line">        V(mutex);  //离开临界区,释放互斥信号量</div><div class="line">        V(full);  //满缓冲区数加1</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">consumer () &#123;  //消费者进程</div><div class="line">    while(1)&#123;</div><div class="line">        P(full);  //获取满缓冲区单元</div><div class="line">        P(mutex);  // 进入临界区</div><div class="line">        remove an item from buffer;  //从缓冲区中取出数据</div><div class="line">        V (mutex);  //离开临界区，释放互斥信号量</div><div class="line">        V (empty) ;  //空缓冲区数加1</div><div class="line">        consume the item;  //消费数据</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="5-线程的实现方式-也就是用户线程与内核线程的区别"><a href="#5-线程的实现方式-也就是用户线程与内核线程的区别" class="headerlink" title="5. 线程的实现方式. (也就是用户线程与内核线程的区别)"></a>5. 线程的实现方式. (也就是用户线程与内核线程的区别)</h4><p><strong>用户线程</strong>：指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应用进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/核心态切换，速度快，操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程（包括它的所有线程）阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少。<br><strong>内核线程</strong>：由操作系统内核创建和撤销。内核维护进程及线程的上下文信息以及线程切换。一个内核线程由于I/O操作而阻塞，不会影响其它线程的运行。Windows NT和2000/XP支持内核线程。<br>用户线程运行在一个中间系统上面。目前中间系统实现的方式有两种，即运行时系统（Runtime System）和内核控制线程。“运行时系统”实质上是用于管理和控制线程的函数集合，包括创建、撤销、线程的同步和通信的函数以及调度的函数。这些函数都驻留在用户空间作为用户线程和内核之间的接口。用户线程不能使用系统调用，而是当线程需要系统资源时，将请求传送给运行时，由后者通过相应的系统调用来获取系统资源。内核控制线程：系统在分给进程几个轻型进程（LWP），LWP可以通过系统调用来获得内核提供的服务，而进程中的用户线程可通过复用来关联到LWP，从而得到内核的服务。</p>
<ul>
<li><strong>以下是用户级线程和内核级线程的区别</strong>：</li>
<li><ul>
<li>内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。</li>
</ul>
</li>
<li><ul>
<li>用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。</li>
</ul>
</li>
<li><ul>
<li>用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。</li>
</ul>
</li>
<li><ul>
<li>在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。</li>
</ul>
</li>
<li><ul>
<li>用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。</li>
</ul>
</li>
<li><p>内核线程的优点：</p>
</li>
<li><ul>
<li>当有多个处理机时，一个进程的多个线程可以同时执行。</li>
</ul>
</li>
<li><p>缺点：</p>
</li>
<li><ul>
<li>由内核进行调度。</li>
</ul>
</li>
<li><p>用户进程的优点：</p>
</li>
<li><ul>
<li>线程的调度不需要内核直接参与，控制简单。</li>
</ul>
</li>
<li><ul>
<li>可以在不支持线程的操作系统中实现。</li>
</ul>
</li>
<li><ul>
<li>创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。</li>
</ul>
</li>
<li><ul>
<li>允许每个进程定制自己的调度算法，线程管理比较灵活。这就是必须自己写管理程序，与内核线程的区别</li>
</ul>
</li>
<li><ul>
<li>线程能够利用的表空间和堆栈空间比内核级线程多。</li>
</ul>
</li>
<li><ul>
<li>同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。另外，页面失效也会产生同样的问题。</li>
</ul>
</li>
<li><p>缺点：</p>
</li>
<li><ul>
<li>资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用</li>
</ul>
</li>
</ul>
<h4 id="6-用户态和核心态的区别。"><a href="#6-用户态和核心态的区别。" class="headerlink" title="6. 用户态和核心态的区别。"></a>6. 用户态和核心态的区别。</h4><p>当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。<br>虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序<br><strong>用户态切换到内核态的3种方式:</strong></p>
<ol>
<li>系统调用<br>这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。</li>
<li>异常<br>当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。</li>
<li>外围设备的中断<br>当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</li>
</ol>
<h4 id="7-用户栈和内核栈的区别。"><a href="#7-用户栈和内核栈的区别。" class="headerlink" title="7. 用户栈和内核栈的区别。"></a>7. 用户栈和内核栈的区别。</h4><p>一个进程有两个堆栈，用户栈和系统栈<br><strong>系统栈</strong>（也叫核心栈、内核栈）是内存中属于操作系统空间的一块区域，其主要用途为：(1)保存中断现场，对于嵌套中断，被中断程序的现场信息依次压入系统栈，中断返回时逆序弹出；(2)保存操作系统子程序间相互调用的参数、返回值、返回点以及子程序(函数)的局部变量。<br><strong>用户栈</strong> 是用户进程空间中的一块区域，用于保存用户进程的子程序间相互调用的参数、返回值、返回点以及子程序(函数)的局部变量。<br>用户堆栈的空间指向用户地址空间，内核堆栈的空间指向内核地址空间。<br>有个CPU堆栈指针寄存器，进程运行的状态有用户态和内核态，当进程运行在用户态时。CPU堆栈指针寄存器指向的是用户堆栈地址，使用的是用户堆栈；当进程运行在内核态时，CPU堆栈指针寄存器指向的是内核堆栈地址，使用的是内核堆栈。<br><strong>堆栈切换</strong><br>当系统因为系统调用（软中断）或硬件中断，CPU切换到特权工作模式，进程陷入内核态，进程使用的栈也要从用户栈转向系统栈。<br>从用户态到内核态要两步骤，首先是将用户堆栈地址保存到内核堆栈中，然后将CPU堆栈指针寄存器指向内核堆栈。<br>当由内核态转向用户态，步骤首先是将内核堆栈中得用户堆栈地址恢复到CPU堆栈指针寄存器中。<br><strong>内核栈和用户栈区别</strong><br>1.栈是系统运行在内核态的时候使用的栈，用户栈是系统运行在用户态时候使用的栈。<br>当进程由于中断进入内核态时，系统会把一些用户态的数据信息保存到内核栈中，当返回到用户态时，取出内核栈中得信息恢复出来，返回到程序原来执行的地方。<br>用户栈就是进程在用户空间时创建的栈，比如一般的函数调用，将会用到用户栈。<br>2.内核栈是属于操作系统空间的一块固定区域，可以用于保存中断现场、保存操作系统子程序间相互调用的参数、返回值等。<br>用户栈是属于用户进程空间的一块区域，用户保存用户进程子程序间的相互调用的参数、返回值等。<br>3.每个Windows 都有4g的进程空间，系统栈使用进程空间的地段部分，用户栈是高端部分如果用户要直接访问系统栈部分，需要有特殊的方式。</p>
<h4 id="8-内存池、进程池、线程池。-c-程序员必须掌握"><a href="#8-内存池、进程池、线程池。-c-程序员必须掌握" class="headerlink" title="8. 内存池、进程池、线程池。(c++程序员必须掌握)"></a>8. 内存池、进程池、线程池。(c++程序员必须掌握)</h4><p><strong>内存池</strong><br>内存池是一种内存分配方式。通常我们习惯直接使用new、malloc等系统调用申请分配内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是，使得内存分配效率得到提升。<br><strong>进程池和线程池</strong><br>进程池和线程池相似，进程池是由服务器预先创建的一组子进程，这些子进程的数目在 3~10 个之间（当然这只是典型情况）。线程池中的线程数量应该和 CPU 数量差不多。<br>进程池中的所有子进程都运行着相同的代码，并具有相同的属性，比如优先级、 PGID 等。<br>当有新的任务来到时，主进程将通过某种方式选择进程池中的某一个子进程来为之服务。相比于动态创建子进程，选择一个已经存在的子进程的代价显得小得多。至于主进程选择哪个子进程来为新任务服务，则有两种方法：<br>1) 主进程使用某种算法来主动选择子进程。最简单、最常用的算法是随机算法和 Round Robin （轮流算法）。<br>2) 主进程和所有子进程通过一个共享的工作队列来同步，子进程都睡眠在该工作队列上。当有新的任务到来时，主进程将任务添加到工作队列中。这将唤醒正在等待任务的子进程，不过只有一个子进程将获得新任务的“接管权”，它可以从工作队列中取出任务并执行之，而其他子进程将继续睡眠在工作队列上。</p>
<p>当选择好子进程后，主进程还需要使用某种通知机制来告诉目标子进程有新任务需要处理，并传递必要的数据。最简单的方式是，在父进程和子进程之间预先建立好一条管道，然后通过管道来实现所有的进程间通信。在父线程和子线程之间传递数据就要简单得多，因为我们可以把这些数据定义为全局，那么它们本身就是被所有线程共享的。<br><strong>线程池主要用于：</strong><br>1）需要大量的线程来完成任务，且完成任务的时间比较短。 比如WEB服务器完成网页请求这样的任务，使用线程池技术是非常合适的。因为单个任务小，而任务数量巨大。但对于长时间的任务，比如一个Telnet连接请求，线程池的优点就不明显了。因为Telnet会话时间比线程的创建时间大多了。<br>2）对性能要求苛刻的应用，比如要求服务器迅速响应客户请求。<br>3）接受突发性的大量请求，但不至于使服务器因此产生大量线程的应用。</p>
<h4 id="9-死锁的概念，导致死锁的原因"><a href="#9-死锁的概念，导致死锁的原因" class="headerlink" title="9. 死锁的概念，导致死锁的原因."></a>9. 死锁的概念，导致死锁的原因.</h4><p><strong>死锁</strong> 指多个进 程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。<br><strong>原因</strong><br>1） 因为系统资源不足;<br>2） 进程运行推进的顺序不合适。<br>3） 资源分配不当等</p>
<h4 id="10-导致死锁的四个必要条件。"><a href="#10-导致死锁的四个必要条件。" class="headerlink" title="10. 导致死锁的四个必要条件。"></a>10. 导致死锁的四个必要条件。</h4><p><strong>互斥</strong> 一次只有一个进程可以使用一个资源。其他进程不能访问已分配给其他进程的资源。<br><strong>占有且等待</strong> 当一个进程等待其他进程时，继续占有已经分配的资源。<br><strong>不可抢占</strong> 不能强行抢占进程已占有的资源。<br><strong>循环等待</strong> 存在一个封闭的进程链，使得每个进程至少占有此链中下一个进程所需要的一个资源。</p>
<h4 id="11-处理死锁的四个方式。"><a href="#11-处理死锁的四个方式。" class="headerlink" title="11. 处理死锁的四个方式。"></a>11. 处理死锁的四个方式。</h4><p>1.忽略该问题。例如鸵鸟算法，该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。<br>2.检测死锁并且恢复。<br>3.仔细地对资源进行动态分配，以避免死锁。<br>4.通过破除死锁四个必要条件之一，来防止死锁产生。</p>
<h4 id="12-预防死锁的方法、避免死锁的方法。"><a href="#12-预防死锁的方法、避免死锁的方法。" class="headerlink" title="12. 预防死锁的方法、避免死锁的方法。"></a>12. 预防死锁的方法、避免死锁的方法。</h4><p>银行家算法是最著名的死锁避免算法。它提出的思想是：把操作系统看做是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源，若没有超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。</p>
<h4 id="13-进程调度算法。"><a href="#13-进程调度算法。" class="headerlink" title="13. 进程调度算法。"></a>13. 进程调度算法。</h4><p><strong>先来先服务(First Come First Service，FCFS)</strong> 调度算法按照进程进入就绪队列的先后顺序选择可以占用处理器的进程。这是一种不可抢占方式的调度算法，优点是实现简单，缺点是后来的进程等待CPU的时间较长。它现今主要用作辅助调度法；例如结合在优先级调度算法中使用，当有两个最高优先级的进程时，则谁先来，谁就先被调度。<br><strong>短执行进程优先算法(Shortest Process First，SPF)</strong> 就是从就绪队列中选择一个CPU执行时间预期最短的进程，将处理器分配给它。虽然较公平，但实现难度较大，因为要准确预定下一个进程的CPU执行周期是很困难的。<br><strong>最高优先级优先(Highest Priority First，HPF)</strong> 调度算法的核心是确定进程的优先级。首先，系统或用户按某种原则为进程指定一个优先级来表示该进程所享有的调度优先权。确定优先级的方法较多，一般可分为两类，即静态法和动态法。静态法根据进程的静态特性，在进程开始执行之前就确定它们的优先级，一旦开始执行之后就不能改变。动态法则不然，它把进程的静态特性和动态特性结合起来确定进程的优先级，随着进程的执行过程，其优先级不断变化。<br>•进程的静态优先级确定最基本的方法是按照进程的类型给予不同的优先级。例如，在有些系统中，进程被划分为系统进程和用户进程。系统进程享有比用户进程高的优先级；对于用户进程来说，则可以分为：I/O繁忙的进程、CPU繁忙的进程、I/O与CPU均衡的进程和其他进程等。<br>•对系统进程，也可以根据其所要完成的功能划分为不同的类型。例如，调度进程、I/O进程、中断处理进程、存储管理进程等。这些进程还可进一步划分为不同类型并赋予不同的优先级。例如，在操作系统中，对于键盘中断的处理优先级和对于电源掉电中断的处理优先级是不相同的。<br>•基于静态优先级的调度算法实现简单，系统开销小，但由于静态优先级一旦确定之后，直到执行结束为止始终保持不变，从而系统效率较低，调度性能不高。现在的操作系统中，如果使用优先级调度的话，则大多采用动态优先级的调度策略。<br>•进程的动态优先级一般可以根据以下两个方面来确定：<br>• (1)根据进程占有CPU时间的长短来决定。一个进程占有处理机的时间愈长，则在被阻塞之后再次获得调度的优先级就越低。反之，其获得调度的可能性就会越大。<br>• (2)根据就绪进程等待CPU的时间长短来决定。一个就绪进程在就绪队列中等待的时间越长，则它获得调度选中的优先级就越高。<br>•由于动态优先级随时间的推移而变化，系统要经常计算各个进程的优先级，因此，系统要为此付出一定的开销。<br>•最高优先级优先调度算法用于多道批处理系统中较好，但它使得优先级较低的进程等待时间较长，这对于分时系统中要想获得较好的响应时间是不允许的，所以在分时系统中多采用时间片轮转法来进行进程调度。<br><strong>时间片轮转(Round Robin，RR)</strong> 法的基本思路是让每个进程在就绪队列中的等待时间与享受服务的时间成比例。在时间片轮转法中，需要将CPU的处理时间分成固定大小的时间片，例如，几十毫秒至几百毫秒。如果一个进程在被调度选中之后用完了系统规定的时间片，但又未完成要求的任务，则它自行释放自己所占有的CPU而排到就绪队列的末尾，等待下一次调度。同时，进程调度程序又去调度当前就绪队列中的第一个进程。<br>•显然，轮转法只能用来调度分配一些可以抢占的资源。这些可以抢占的资源可以随时被剥夺，而且可以将它们再分配给别的进程。CPU是可抢占资源的一种。但打印机等资源是不可抢占的。由于作业调度是对除了CPU之外的所有系统硬件资源的分配，其中包含有不可抢占资源，所以作业调度不使用轮转法。在轮转法中，时间片长度的选取非常重要。首先，时间片长度的选择会直接影响到系统的开销和响应时间。如果时间片长度过短，则调度程序抢占处理机的次数增多。这将使进程上下文切换次数也大大增加，从而加重系统开销。反过来，如果时间片长度选择过长，例如，一个时间片能保证就绪队列中所需执行时间最长的进程能执行完毕，则轮转法变成了先来先服务法。时间片长度的选择是根据系统对响应时间的要求和就绪队列中所允许最大的进程数来确定的。<br>•在轮转法中，加入到就绪队列的进程有3种情况，一种是分给它的时间片用完，但进程还未完成，回到就绪队列的末尾等待下次调度去继续执行。另一种情况是分给该进程的时间片并未用完，只是因为请求I/O或由于进程的互斥与同步关系而被阻塞。当阻塞解除之后再回到就绪队列。第三种情况就是新创建进程进入就绪队列。如果对这些进程区别对待，给予不同的优先级和时间片，从直观上看，可以进一步改善系统服务质量和效率。例如，我们可把就绪队列按照进程到达就绪队列的类型和进程被阻塞时的阻塞原因分成不同的就绪队列，每个队列按FCFS原则排列，各队列之间的进程享有不同的优先级，但同一队列内优先级相同。这样，当一个进程在执行完它的时间片之后，或从睡眠中被唤醒以及被创建之后，将进入不同的就绪队列。</p>
<h4 id="14-Windows内存管理的方式-块式、页式、段式、段页式"><a href="#14-Windows内存管理的方式-块式、页式、段式、段页式" class="headerlink" title="14. Windows内存管理的方式(块式、页式、段式、段页式)."></a>14. Windows内存管理的方式(块式、页式、段式、段页式).</h4><p><strong>块式管理</strong> 把主存分为一大块、一大块的，当所需的程序片断不在主存时就分配一块主存空间，把程 序片断load入主存，就算所需的程序片度只有几个字节也只能把这一块分配给它。这样会造成很大的浪费，平均浪费了50％的内存空间，但时易于管理。<br><strong>页式管理</strong> 的基本原理是将各进程的虚拟空间划分为若干个长度相等的页；页式管理把内存空间按照页的大小划分成片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表；并用相应的硬件地址变换机构来解决离散地址变换问题。页式管理采用请求调页或预调页技术来实现内外存存储器的统一管理。其优点是没有外碎片，每个内碎片不超过页的大小。缺点是,程序全部装入内存，要求有相应的硬件支持。例如地址变换机构缺页中断的产生和选择淘汰页面等都要求有相应的硬件支持。这增加了机器成本，增加了系统开销。<br><strong>段式管理</strong> 的基本思想是把程序按照内容或过程函数关系分段，每段都有自己的名字。一个用户作业或进程所包括的段对应一个二维线形虚拟空间，也就是一个二维虚拟存储器。段式管理程序以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。其优点是可以分别编写和编译，可以针对不同类型的段采用不同的保护，可以按段为单位来进行共享，包括通过动态链接进行代码共享。缺点是会产生碎片。<br><strong>段页式管理</strong> 为了实现段页式管理，系统必须为每个作业或进程建立一张段表以管理内存分配与释放、缺段处理等。另外由于一个段又被划分成了若干个页。每个段必须建立一张页表以把段中的虚页变换成内存中的实际页面。显然与页式管理时相同，页表中也要有相应的实现缺页中断处理和页面保护等功能的表项。段页式管理的段式管理与页式管理方案结合而成的所以具有他们两者的优点。但反过来说，由于管理软件的增加，复杂性和开销也就随之增加了。另外需要的硬件以及占用的内存也有所增加。使得速度降下来。</p>
<h4 id="15-内存连续分配方式采用的几种算法及各自优劣。"><a href="#15-内存连续分配方式采用的几种算法及各自优劣。" class="headerlink" title="15. 内存连续分配方式采用的几种算法及各自优劣。"></a>15. 内存连续分配方式采用的几种算法及各自优劣。</h4><p>单一连续分配：只能用于单用户、单任务的操作系统中。<br>固定分区分配：可运行多道程序的存储管理方式。<br>动态分区分配：根据进程的实际需要，动态地为之分配内存空间。<br>可重定位分区分配：必须把一个系统或用户程序装入一连续的内存空间。<br>（1）首次适应算法。使用该算法进行内存分配时，从空闲分区链首开始查找，直至找到一个能满足其大小需求的空闲分区为止。然后再按照作业的大小，从该分区中划出一块内存分配给请求者，余下的空闲分区仍留在空闲分区链中。<br>　　该算法倾向于使用内存中低地址部分的空闲分区，在高地址部分的空闲分区非常少被利用，从而保留了高地址部分的大空闲区。显然为以后到达的大作业分配大的内存空间创造了条件。缺点在于低址部分不断被划分，留下许多难以利用、非常小的空闲区，而每次查找又都从低址部分开始，这无疑会增加查找的开销。<br>　　（2）循环首次适应算法。该算法是由首次适应算法演变而成的。在为进程分配内存空间时，不再每次从链首开始查找，而是从上次找到的空闲分区开始查找，直至找到一个能满足需求的空闲分区，并从中划出一块来分给作业。该算法能使空闲中的内存分区分布得更加均匀，但将会缺乏大的空闲分区。<br>　　（3）最佳适应算法。该算法总是把既能满足需求，又是最小的空闲分区分配给作业。<br>　　为了加速查找，该算法需求将所有的空闲区按其大小排序后，以递增顺序形成一个空白链。这样每次找到的第一个满足需求的空闲区，必然是最优的。孤立地看，该算法似乎是最优的，但事实上并不一定。因为每次分配后剩余的空间一定是最小的，在存储器中将留下许多难以利用的小空闲区。同时每次分配后必须重新排序，这也带来了一定的开销。<br>　　最坏适应算法和最佳适应算法的排序正好相反，他的队列指针总是指向最大的空闲区，在进行分配时，总是从最大的空闲区开始查寻。<br>　　该算法克服了最佳适应算法留下的许多小的碎片的不足，但保留大的空闲区的可能性减小了，而且空闲区回收也和最佳适应算法相同复杂。</p>
<h4 id="16-动态链接及静态链接"><a href="#16-动态链接及静态链接" class="headerlink" title="16. 动态链接及静态链接."></a>16. 动态链接及静态链接.</h4><p>所谓静态链接就是在编译链接时直接将需要的执行代码拷贝到调用处，优点就是在程序发布的时候就不需要的依赖库，也就是不再需要带着库一块发布，程序可以独立执行，但是体积可能会相对大一些。（所谓库就是一些功能代码经过编译连接后的可执行形式。）<br>所谓动态链接就是在编译的时候不直接拷贝可执行代码，而是通过记录一系列符号和参数，在程序运行或加载时将这些信息传递给操作系统，操作系统负责将需要的动态库加载到内存中，然后程序在运行到指定的代码时，去共享执行内存中已经加载的动态库可执行代码，最终达到运行时连接的目的。优点是多个程序可以共享同一段代码，而不需要在磁盘上存储多个拷贝，缺点是由于是运行时加载，可能会影响程序的前期执行性能。</p>
<h4 id="17-基本分页、请求分页储存管理方式。"><a href="#17-基本分页、请求分页储存管理方式。" class="headerlink" title="17. 基本分页、请求分页储存管理方式。"></a>17. 基本分页、请求分页储存管理方式。</h4><p>请求分页储存管理是实现虚拟存储器的一种常用方式，它是在基本分页储存管理的基础上实现的。其基本思想是：在进程开始运行之前，仅装入当前要执行的部分页面即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的页面；当内存空间已满，而又需要装入新的页面时，者根据置换功能适当调出某个页面，以便腾出空间而装入新的页面。为实现请求分页，需要一定的硬件支持，包括：页表机制、缺页中断机构、地址变换机构。<a href="http://baike.baidu.com/link?url=gipKeBkgSpqVfK9FBDQx7iDpJRGEFL5vVqIoRwN9EM-8Zz6QjDaF4OhQ3tJQha5b70_ex1H1LRcoDq2nLM4jya" target="_blank" rel="external">具体内容</a></p>
<h4 id="18-基本分段、请求分段储存管理方式。"><a href="#18-基本分段、请求分段储存管理方式。" class="headerlink" title="18. 基本分段、请求分段储存管理方式。"></a>18. 基本分段、请求分段储存管理方式。</h4><h4 id="19-分段分页方式的比较各自优缺点。"><a href="#19-分段分页方式的比较各自优缺点。" class="headerlink" title="19. 分段分页方式的比较各自优缺点。"></a>19. 分段分页方式的比较各自优缺点。</h4><p>1）页是信息的物理单位，分页是为实现离散分配方式，消减外部碎片，提高内存的利用率。分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了更好的满足用户的需要。<br>2）页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。<br>3）分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。<br><strong>连续</strong> 设计简单，直接寻址，效率高。缺点：内存利用效率最低。<br><strong>分页</strong> 设计最复杂，容易产生碎片，无论数据有多少，都只能按照页面大小分配，造成浪费。<br><strong>分段</strong> 可以有效利用内存，缺点，无法利用碎片，必须搬移内存，造成性能损失。</p>
<h4 id="20-几种页面置换算法，会算所需换页数。-LRU用程序如何实现？"><a href="#20-几种页面置换算法，会算所需换页数。-LRU用程序如何实现？" class="headerlink" title="20. 几种页面置换算法，会算所需换页数。(LRU用程序如何实现？)"></a>20. 几种页面置换算法，会算所需换页数。(LRU用程序如何实现？)</h4><p><strong>随机淘汰算法(random golongram):</strong> 在系统设计人员认为无法确定哪些页被访问的概率较低时，随机地选择某个用户的页面并将其换出将是一种明智的作法。<br><strong>轮转法(RR,round robin)</strong> :轮转法循回换出内存可用区内一个可以被换出的页，无论该页是刚被换进或已换进内存很长时间。FIFO算法总是选择在内存驻留时间最长的一员将其淘汰。<br><strong>FIFO算法</strong> 认为先调入内存的页不再被访问的可能性要比其它页大，因而选择最先调入内存的页换出。实现FIFO算法需要把各个已分配页面按分配时间顺序链接起来，组成FIFO队列，并设置一置换指针指向FIFO队列的队首页面。这样，当要进行置换时，只需把置换指针所指的FIFO队列前头的页顺次换出，而把换入的页链接在FIFO队尾即可。<br>由实验和测试发现FIPO算法和RR算法的内存利用率不高。这是因为，这两种算法都是基于CPU按线性顺序访问地址空间这一假设。事实上，许多时候．CPU不是按线性顺序访问地址空间的。<br><strong>Belady现象:</strong> 一般来说，对于任一作业或进程，如果给它分配的内存页面数越接近于它所要求的页面数，则发生缺页的次数会越少。在极限情况下，这个推论是成立的。因为如果给一个进程分配了它所要求的全部页面，则不会发生缺页现象。但是，使用FIFO算法时，在未给进程或作业分配足它所要求的页面数时，有时会出现分配的页面数增多，缺页次数反而增加的奇怪现象。这种现象称为Belady现象。<br><strong>最近最久未使用页面置换算法(LRU, Least Recently Used):</strong><br>选择内存中最久未使用的页面被置换。这是局部性原理的合理近似，性能接近最佳算法。但由于需要记录页面使用时间的先后关系，硬件开销太大。硬件机构如：<br>(1) 一个特殊的栈：把被访问的页面移到栈顶，于是栈底的是最久未使用页面。<br>(2) 每个页面设立移位寄存器：被访问时左边最高位置1，定期右移并且最高位补0，于是寄存器数值最小的是最久未使用页面。<br>比较常用的近似算法有：<br>(a) 最不经常使用页面淘汰算法(LFU, Least Frequently Used)<br>(b) 最近没有使用页面淘汰(NRU, Not Recently Used)<br><strong>理想型淘汰算法（OPT,Optimal Replacement Algorithm）</strong><br>该算法淘汰在访问串中将来再也不出现的或是离当前最远的位置上出现的页。它是一种理想化的算法，性能最好，但在实际上难于实现。</p>
<h4 id="21-虚拟内存的定义及实现方式。"><a href="#21-虚拟内存的定义及实现方式。" class="headerlink" title="21. 虚拟内存的定义及实现方式。"></a>21. 虚拟内存的定义及实现方式。</h4><p><strong>定义</strong> 基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。<br><strong>实现方式：</strong><br>虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：</p>
<ul>
<li>请求分页存储管理。</li>
<li>请求分段存储管理。</li>
<li>请求段页式存储管理。</li>
</ul>
<p>不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：</p>
<ul>
<li>一定容量的内存和外存。</li>
<li>页表机制（或段表机制），作为主要的数据结构。</li>
<li>中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。</li>
<li>地址变换机构，逻辑地址到物理地址的变换。</li>
</ul>
<h4 id="22-操作系统的四个特性。"><a href="#22-操作系统的四个特性。" class="headerlink" title="22. 操作系统的四个特性。"></a>22. 操作系统的四个特性。</h4><p><strong>并发（concurrence）</strong><br>并行性与并发性这两个概念是既相似又区别的两个概念。并行性是指两个或者多个事件在同一时刻发生，这是一个具有微观意义的概念，即在物理上这些事件是同时发生的；而并发性是指两个或者多个事件在同一时间的间隔内发生，它是一个较为宏观的概念。在多道程序环境下，并发性是指在一段时间内有多道程序在同时运行，但在单处理机的系统中，每一时刻仅能执行一道程序，故微观上这些程序是在交替执行的。   应当指出，通常的程序是静态实体，它们是不能并发执行的。为了使程序能并发执行，系统必须分别为每个程序建立进程。进程，又称任务，简单来说，是指在系统中能独立运行并作为资源分配的基本单位，它是一个活动的实体。多个进程之间可以并发执行和交换信息。一个进程在运行时需要运行时需要一定的资源，如 cpu,存储空间，及i/o设备等。在操作系统中引入进程的目的是使程序能并发执行。<br><strong>共享 (sharing)</strong><br>所谓共享是指，系统中的资源可供内存中多个并发执行的进程共同使用。由于资源的属性不同，故多个进程对资源的共享方式也不同，可以分为：互斥共享方式 和 同时访问方式<br><strong>虚拟 (virtual)</strong><br>是指通过技术吧一个物理实体变成若干个逻辑上的对应物。在操作系统中虚拟的实现主要是通过分时的使用方法。显然，如果n是某一个物理设备所对应的虚拟逻辑设备数，则虚拟设备的速度必然是物理设备速度的1/n。<br><strong>异步 (asynchronism)</strong><br>在多道程序设计环境下，允许多个进程并发执行，由于资源等因素的限制，通常，进程的执行并非“一气呵成”，而是以“走走停停”的方式运行。内存中每个进程在何时执行，何时暂停，以怎样的方式向前推进，每道程序总共需要多少时间才能完成，都是不可预知的。或者说，进程是以一步的方式运行的。尽管如此，但只要运行环境相同，作业经过多次运行，都会获得完全相同的结果。</p>
<h4 id="23-DMA。"><a href="#23-DMA。" class="headerlink" title="23. DMA。"></a>23. <a href="http://baike.baidu.com/link?url=NS_qtnUb3Vj5bvNPN2Yk5-7kyJ0YPEpX5ywm-QKm1e2Y5U0D9ZzqXDyYFRDP5A2X9M3u9g8soOz5QP83l55myrvn_K2KE1sRAtKtxV8omCK" target="_blank" rel="external">DMA</a>。</h4><p>DMA的英文拼写是“Direct Memory Access”，汉语的意思就是直接内存访问，是一种不经过CPU而直接从内存存取数据的数据交换模式。在DMA模式下，CPU只须向DMA控制器下达指令，让DMA控制器来处理数据的传送，数据传送完毕再把信息反馈给CPU，这样就很大程度上减轻了CPU资源占有率，可以大大节省系统资源</p>
<h4 id="24-Spooling。"><a href="#24-Spooling。" class="headerlink" title="24. Spooling。"></a>24. Spooling。</h4><p>SPOOLing技术是低速输入输出设备与主机交换的一种技术，通常也称为“假脱机真联机”，他的核心思想是以联机的方式得到脱机的效果。低速设备经通道和外设在主机内存的缓冲存储器与高速设备相联，该高速设备通常是辅存。为了存放从低速设备上输入的信息，或者存放将要输出到低速设备上的信息（来自内存），在辅存分别开辟一固定区域，叫“输出井”（对输出），或者“输入井”（对输入）。简单来说就是在内存中形成缓冲区，在高级设备形成输出井和输入井，传递的时候，从低速设备传入缓冲区，再传到高速设备的输入井，再从高速设备的输出井，传到缓冲区，再传到低速设备。<br><strong>SPOOLing系统主要有以下三部分：</strong><br>（1）输入井和输出井。这是在磁盘上开辟的两个大存储空间。输入井是模拟脱机输入时的磁盘设备，用于暂存I/Q设备输入的数据；输出井是模拟脱机输出时的磁盘，用于暂存用户程序的输出数据。<br>（2）输入缓冲区和输出缓冲区。为了缓和和CPU和磁盘之间速度不匹配的矛盾，在内存中要开辟两个缓冲区；输入缓冲区和输出缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用与暂存从输出井送来的数据，以后在传送给输出设备。<br>（3）输入进程SPi 和输入进程SP0。这里利用两个进程来模拟脱机I/O时的外围控制机。其中，进程SPi模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再送到输入井，当CPU需要输入数据时，直接从输入井读入内存；进程SP0模拟脱机输出时的外围控制机，把用户要求输出的数据从先内存送到输出井，待输出设备空闲时，在将输出井中的数据经过输出缓冲区送到输出设备上。<br><strong>SPOOLing技术的特点：</strong><br>(1)提高了I/O速度。从对低速I/O设备进行的I/O操作变为对输入井或输出井的操作，如同脱机操作一样，提高了I/O速度，缓和了CPU与低速I/O设备速度不匹配的矛盾。<br>(2)将独占设备改造为共享设备。因为在SPOOLing系统的系统中，实际上并没为任何进程分配设备，而知识在输入井或输出井中为进程分配一个存储区和建立一张I/O请求表。这样，便把独占设备改造为共享设备。<br>(3)实现了虚拟设备功能。多个进程同时使用一独享设备，而对每一进程而言，都认为自己独占这一设备，从而实现了设备的虚拟分配。不过，该设备是逻辑上的设备。</p>
<h4 id="25-外存分配的几种方式，及各种优劣"><a href="#25-外存分配的几种方式，及各种优劣" class="headerlink" title="25. 外存分配的几种方式，及各种优劣"></a>25. <a href="http://blog.csdn.net/liuqiyao_01/article/details/39156651" target="_blank" rel="external">外存分配的几种方式，及各种优劣</a></h4><p><strong>连续分配</strong><br>原理：创建文件时，分配一组连续的块；FAT（文档分配表）中每个文件只要一项，说明起始块和文件长度。对于顺序文件有利。<br>优点: 1.简便。适用于一次性写入操作。2.支持顺序存取和随机存取，顺序存取速度快。3.所需的磁盘寻道次数和寻道时间最少。（因为空间的连续性，当访问下一个磁盘块时，一般无需移动磁头，当需要移动磁头时，只需要移动一个磁道。）<br>缺点：1.文件不能动态增长。（可能文件末尾处的空块已经分配给了别的文件。）2.不利于文件的插入和删除。3.外部碎片问题。（反复增删文件后，很难找到空间大小足够的连续块，需要进行紧缩。）4.在创建文件时需生命文件大小。<br><strong>链式分配</strong><br>原理：一个文件的信息存放在若干个不连续的物理块中，各块之间通过指针连接，前一个物理块指向下一个物理块。fat中每个文件同样只需要一项，包括文件名、起始块号和最后块号。任何一个自由块都可以加入到链中。<br>优点：1.提高磁盘的空间利用率，不存在外部碎片问题。2.有利于文件的插入和删除。3.有利于文件的动态扩充。<br>缺点：1.存取速度慢，一般只适用于信息的顺序存取，不适于随机存取。2.查找某一块必须从头到尾沿着指针进行。3.可靠性问题，如指针出错。4.更多的寻道次数和寻道时间。5.链接指针占一定的空间，将多个块组成簇，按簇进行分配而不是按块进行分配。（增加了磁盘碎片）<br><strong>索引分配</strong><br>原理：每个文件在FAT中有一个一级索引，索引包含分配给文件的每个分区的入口。文件的索引保存在单独的一个块中，FAT中该文件的入口指向这一块。<br>优点：1.保持了链接结构的优点，又解决了其缺点：按快分配可以消除外部碎片。按大小可改变的分区分配可以提高局部性。索引分配支持顺序访问文件和直接访问文件，是普遍采用的一种方式。2.满足了文件动态增长，插入删除的要求。（只要有空闲块）3.能充分利用外存空间。<br>缺点：1.较多的寻道次数和寻道空间。2.索引表本身带来了系统开销，如：内外存空间、存取时间。<br><strong>连续分配和索引分配相结合</strong><br>原理：对于小文件（3、4块），采用连续分配；当文件大时，自动切换到索引分配。<br>文件的直接访问：使用连续分配方式。<br>文件的顺序访问：采用链接分配。    对于这些系统，所使用的访问类型，必须在文件创建时加以说明。<br><strong>多重索引</strong><br>原理：首先，多重索引也是索引分配的一种，只不过它是将一个大文件的所有索引表（二级索引）的地址放在另一个索引表（一级索引）中。ps：跟数据库第四范式非常像。<br>大文件：设一个盘块大小为1kb，长度100kb的文件就需要100个盘块，索引表至少需要100项；若文件大小为1000kb，则索引表项就要有1000项。设盘块号用4个字节表示，则该索引表至少占用4000bye（约4k）。<br>当文件很大时，存在的问题：1.需要很多磁盘块。2.索引表很大。3.不能将整个索引表放在内存。<br>解决途径：采用多重索引表结构。</p>
<hr>
<h1 id="二：计算机网络"><a href="#二：计算机网络" class="headerlink" title="二：计算机网络"></a>二：计算机网络</h1><h4 id="1-电路交换与分组交换的区别？-优劣对比。"><a href="#1-电路交换与分组交换的区别？-优劣对比。" class="headerlink" title="1. 电路交换与分组交换的区别？ 优劣对比。"></a>1. 电路交换与分组交换的区别？ 优劣对比。</h4><p><strong>电路交换：</strong><br>电路交换是以电路连接为目的的交换方式，通信之前要在通信双方之间建立一条被双方独占的物理通道。<br>电路交换的三个阶段：<br>    （1）建立连接    （2）通信    （3）释放连接<br>    电路交换具有以下优缺点：<br><em>优点：</em><br>    （1）由于通信线路为通信双方用户专用，数据直达，所以传输数据的时延非常小。<br>    （2）通信双方之间的屋里通路一旦建立，双方可以随时通信，实时性强。<br>    （3）双方通信时按发送顺序传送数据，不存在失序问题。<br>    （4）电路交换既适用于传输模拟信号，也适用于传输数字信号。<br>    （5）电路交换的交换设备及控制均比较简单。<br><em>缺点：</em><br>    （1）电路交换平均连接建立时间对计算机通信来说较长。<br>    （2）电路交换家里连接后，物理通路被通信双方独占，即使通信线路空闲，也不能供其他用户使用，因而信道利用率低。<br>    （3）电路交换时，数据直达，不同类型，不同规格，不同速率的终端很难相互进行通信，也难以在通信过程中进行差错控制。<br>    <strong>分组交换</strong><br>      分组交换是以分组为单位进行传输和交换的，它是一种存储——转发交换方式，即将到达交换机的分组先送到存储器暂时存储和处理，等到相应的输出电路有空闲时再送出。<br>    分组交换具有以下优缺点。<br><em>优点：</em><br>    （1）分组交换不需要为通信双反预先建立一条专用的通信线路，不存在连接建立时延，用户可随时发送分组。<br>    （2）由于采用存储转发方式，加之交换节点具有路径选择，当某条传输线路故障时可选择其他传输线路，提高了传输的可靠性。<br>    （3）通信双反不是固定的战友一条通信线路，而是在不同的时间一段一段地部分占有这条物理通路，因而大大提高了通信线路的利用率。<br>    （4）加速了数据在网络中的传输。因而分组是逐个传输，可以使后一个分组的存储操作与前一个分组的转发操作并行，这种流水线式传输方式减少了传输时间。<br>    （5）分组长度固定，相应的缓冲区的大小也固定，所以简化了交换节点中存储器的管理。<br>    （6）分组较短，出错几率减少，每次重发的数据量也减少，不仅提高了可靠性，也减少了时延。<br><em>缺点：</em><br>    （1）由于数据进入交换节点后要经历存储转发这一过程，从而引起的转发时延（包括接受分组、检验正确性、排队、发送时间等），而且网络的通信量越大，造成的时延就越大，实时性较差。<br>    （2）分组交换只适用于数字信号。<br>    （3）分组交换可能出现失序，丢失或重复分组，分组到达目的节点时，对分组按编号进行排序等工作，增加了麻烦。<br>    综上，若传输的数据量很大，而且传送时间远大于呼叫时间，则采用电路交换较为合适；当端到端的通路有很多段链路组成是，采用分组交换较为合适。从提高整个网络的信道利用率上看，分组交换优于电路交换。</p>
<h4 id="2-OSI有哪几层，会画出来，知道主要几层的各自作用。"><a href="#2-OSI有哪几层，会画出来，知道主要几层的各自作用。" class="headerlink" title="2. OSI有哪几层，会画出来，知道主要几层的各自作用。"></a>2. OSI有哪几层，会画出来，知道主要几层的各自作用。</h4><p>OSI有七层：<br>一层：物理层—负责传送比特，涉及到接口和传输媒体的机械、电气等特性。<br>二层：数据链路层—负责传送帧<br>三层：网络层—负责路由、传送分组。<br>四层：传输层—负责传送完整的报文，并进行流量控制和差错控制。<br>五层：会话层—负责建立、维护、终止会话连接，提供会话管理服务等。<br>六层：表示层—负责数据格式的转换。<br>七层：应用层—应用层给应用程序提供了接口，使应用程序接入到网络。</p>
<h4 id="3-TCP-IP有哪几层，会画出来，知道所有层数的作用，会列举各层主要的协议名称。"><a href="#3-TCP-IP有哪几层，会画出来，知道所有层数的作用，会列举各层主要的协议名称。" class="headerlink" title="3. TCP/IP有哪几层，会画出来，知道所有层数的作用，会列举各层主要的协议名称。"></a>3. TCP/IP有哪几层，会画出来，知道所有层数的作用，会列举各层主要的协议名称。</h4><p>1、网络接口层<br>     物理层定义与传输媒体的接口有关的一些特性，即机械特性、电气特性、功能特性、过程特性，并需要完成并行传输和串行传输之间的转换。<br>     数据链路层向该层用户提供透明的和可靠的数据传输服务。 透明性是指该层上传输的数据的内容、格式及编码没有限制，也没有必要解释信息结构的意义；可靠性是指在传输过程中将物理层提供的可能出错的物理连接改造成为逻辑上无差错的数据链路，其具体的方法有帧同步、差错控制、流量控制、链路管理。<br>     物理层中主要的宽带接入技术有xdsl、光纤同轴混合网（HFC）、FTTx技术<br>     数据链路层中的主要协议有点对点协议PPP，CSMA/CD协议，以太网802.3。<br>2、网际层<br>     网际层向上值提供简单灵活的、无连接的、尽最大努力交付的数据报服务。网际层不提供服务质量的承诺，即所传输的分组可能出错、丢失、重复和失序，当然也不保证分组交付的时限。<br>     网际层中主要协议有IP协议，地址解析协议ARP和逆地址解析协议RARP，网际控制报文协议ICMP。<br>     IP协议是网际层的核心，通过路由选择将下一跳IP封装后交给网络接口层。IP 数据报是无连接服务。<br>     ICMP是网际层的补充，可以回送报文。用来检测网络是否通畅（使用ping命令）。<br>     ARP是通过已知IP，寻找对于主机的MAC地址。<br>     RARP是通过过MAC地址确定IP地址。<br>3、运输层<br>     运输层为应用进程之间 提供端到端的逻辑通信，并具有复用和分用的功能，即发送方不同的应用进程都可以使用听一个运输层协议传送数据；接收方的运输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程。运输层还将对报文进行差错控制，以提高可靠传输。<br>     运输层中主要协议有用户数据报协议UDP和传输控制协议TCP<br>4、应用层<br>     应用层为用户提供应用程序。<br>     应用层中主要协议有域名系统DNS，文件传输协议FTP，远程终端协议TELNET，超文本传输协议HTTP，简单邮件传送协议SMTP，邮件读取协议POP3和IMAP，动态主机配置协议DHCP，简单网络管理协议SNMP。<br>     DNS：提供域名解析服务，提供域名到IP地址之间的转换，使用端口53<br>     FTP：在异构网络中任意计算机之间传送文件，使用端口21<br>     TELNET：提供用户远程登录服务，使用端口23，使用明码传送，保密性差、简单方便<br>     HTTP：用于实现万维网上的各种链接，即万维网客户程序与万维网服务器之间的连接，使用端口80<br>     SMTP/POP3、IMAP：提供邮件的传输，用来控制信件的发送、中转/从邮件服务器读取邮件。<br>     DHCP：为新加入网络的计算机自动分配IP地址。<br>     SNMP：管理互联网Internet上众多厂家生产的软硬件平台</p>
<h4 id="4-硬件-MAC-地址的概念及作用。"><a href="#4-硬件-MAC-地址的概念及作用。" class="headerlink" title="4. 硬件(MAC)地址的概念及作用。"></a>4. 硬件(MAC)地址的概念及作用。</h4><p>MAC地址就是在媒体接入层上使用的地址，也叫物理地址、硬件地址或链路地址，其被固化在适配器的ROM中。可见MAC地址实际上就是适配器地址或适配器标识符。当某台计算机使用某块适配器后，适配器上的标识符就成为该计算机的MAC地址。MAC地址长度为6字节（48比特），由IEEE的注册管理结构RA进行管理分配。<br>作用：MAC地址是计算机的唯一标识，在数据链路层中，交换机通过识别MAC地址进行数据包的传输。</p>
<h4 id="5-ARP协议的用途-及算法、在哪一层上会使用arp-？"><a href="#5-ARP协议的用途-及算法、在哪一层上会使用arp-？" class="headerlink" title="5. ARP协议的用途 及算法、在哪一层上会使用arp ？"></a>5. ARP协议的用途 及算法、在哪一层上会使用arp ？</h4><p>ARP协议的用途：解决同一个局域网内主机或路由器的IP地址和MAC地址的映射问题。<br>算法：在主机的ARP高速缓存中应存放一个从IP地址到MAC地址的映射表，并且这个映射表还经常动态更新（新增或超时删除）。<br>在网络层会使用ARP。</p>
<h4 id="6-CRC冗余校验算法-反码和检验算法"><a href="#6-CRC冗余校验算法-反码和检验算法" class="headerlink" title="6. CRC冗余校验算法,[反码和检验算法]"></a>6. <a href="http://blog.163.com/flx_wchy/blog/static/127122077201022212213520/" target="_blank" rel="external">CRC冗余校验算法</a>,[反码和检验算法]</h4><p>反码求和校验：<br>　　反码求和的过程更简单一些，将原始信息每16bit取反，求和，结果存在检验和字段中，接收端同样对每个16bit进行二进制反码求和，接收方在计算中包含发送方存放的检验和，最终结果应该全为1.<br>　　为何全为1？我们简化4位模拟该过程。假设发送端有1001，取反后0110，最终发送10010110，接收端收到后开始校验，取反求和<br>0110 ＋ 1001＝1111<br>　　结果如预期所料。其实更重要的是，当遇到进位时的处理，反码求和最高位遇到进位时，最高位进位后放到低位继续求和。意味着对于四位的求和，超过1111则循环到1，这就是反码补码的时钟循环原理，1111是4位反码求和的最大数。一个数加上自己取反得到的数正是时钟轮盘上最大那个数。接收端由于包含了发送端计算的反码和。反码和取反＋反码和 ＝ 全1.</p>
<h4 id="7-如何实现透明传输。"><a href="#7-如何实现透明传输。" class="headerlink" title="7. 如何实现透明传输。"></a>7. 如何实现透明传输。</h4><p>透明传输的基本概念：<br>数据透明传输就是用户不受协议中的任何限制，可随机的传输任意比特编码的信息<br>用户可以完全不必知道协议中所规定的结束段的比特编码或者其他的控制字符，因而不受限制的进行传输。<br>数据透明传输技术：<br>转义字符填充法<br>零比特填充法<br>采用特殊的信号与编码法：IEEE802.3(由于使用CSMA/CD协议，没有结束字符段；IEEE802.4（令牌总线，在起始定界符SD/结束定界符ED这两个字段被使用模拟编码，而不是0和1）；IEEE802.5（令牌环，违例的曼切斯特码）<br>确定长度法，固定数据段长度法：各控制字段的长度固定，数据段长度也是固定的，那么在帧格式中就不必设结束符，也不必设数据长度字段。</p>
<h4 id="8-知道各个层使用的是哪个数据交换设备。（交换机、路由器、网关）"><a href="#8-知道各个层使用的是哪个数据交换设备。（交换机、路由器、网关）" class="headerlink" title="8. 知道各个层使用的是哪个数据交换设备。（交换机、路由器、网关）"></a>8. 知道各个层使用的是哪个数据交换设备。（交换机、路由器、网关）</h4><p>物理层用到的设备是集线器和中继器<br>数据链路层用到的设备是交换机和网桥<br>网络层用到的设备是路由器<br>应用层用到的设备是网关<br>中继器的主要功能是对接收到的信号进行再生整形放大以扩大网络的传输距离。<br>集线器在此基础上将所有的节点集中在以它为中心的节点中，可组成星型拓扑结构。<br>交换机是一种基于MAC识别，能完成封装转发数据包功能的网络设备。它可以“学习”MAC地址，并把其存放在内部地址表中，当一个数据帧的目的地址在MAC地址表中有映射时，它被转发到连接目的节点的端口而不是所有端口。交换机将局域网分为多个冲突域，每个冲突域都是有独立的宽带，因此大大提高了局域网的带宽。<br>网桥是数据链路层互联的设备，在网络互联中可起到数据接收、地址过滤与数据转发的作用，可用来实现多个不同网络系统之间的数据交换。<br>路由器用于连接多个逻辑上分开的网络，具有判断网络地址和选择IP路径的功能，它能在多网络互联环境中，建立灵活的连接，可用完全不同的数据分组和介质访问方法连接各种子网。<br>网关在网络层以上实现网络互连，用于两个高层协议不同的网络互连。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。</p>
<h4 id="9-路由表的内容。"><a href="#9-路由表的内容。" class="headerlink" title="9. 路由表的内容。"></a>9. 路由表的内容。</h4><p>destination mask pre costdestination：目的地址，用来标识IP包的目的地址或者目的网络。<br>mask：网络掩码，与目的地址一起标识目的主机或者路由器所在的网段的地址。<br>pre：标识路由加入IP路由表的优先级。可能到达一个目的地有多条路由，但是优先级的存在让他们先选择优先级高的路由进行利用。<br>cost：路由开销，当到达一个目的地的多个路由优先级相同时，路由开销最小的将成为最优路由。<br>interface：输出接口，说明IP包将从该路由器哪个接口转发。<br>nexthop：下一跳IP地址，说明IP包所经过的下一个路由器。</p>
<h4 id="10-分组转发算法。"><a href="#10-分组转发算法。" class="headerlink" title="10. 分组转发算法。"></a>10. 分组转发算法。</h4><p>1、从数据报的首部提取目的主机的IP地址D，计算出目的主机的网络地址N。(将IP数据报中目的主机的IP地址和路由表上的子网掩码进行&amp;运算，就可以得出网络地址N)<br>2、若N就是与此路由器直接相连的某个网络的网络地址。则直接进行交付，不需要经过其他路由器，而是直接将IP数据报交付给目的主机。(注意，直接交付时，路由器需要将目的主机地址D转换为具体的硬件地址，把数据报封装在MAC帧，在发送此帧。)若N不是与此路由器直接相连的网络，就进行间接交付。执行3或执行4<br>3、若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行4.(这是特殊情况)<br>4、若路由表中有到达网络N的路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行5。<br>5、如果3和4都没能将IP数据报转发出去，若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行6<br>6、报告转发分组出错。</p>
<h4 id="11-IP报文的格式，格式的各个字段的含义要理解。"><a href="#11-IP报文的格式，格式的各个字段的含义要理解。" class="headerlink" title="11. IP报文的格式，格式的各个字段的含义要理解。"></a>11. IP报文的格式，格式的各个字段的含义要理解。</h4><p>1、版本<br>     占4位，指IP协议的版本。<br>2、报头长度<br>     占4位，该字段的单位是32位字（1个32位字长是4字节），因此当IP报头长度为1111时，报头长度就达到最大值60字节。当IP分组的首部长度不是4字节的整数倍是，就需要对填充域加以填充。最常用的报头长度为20位(报头长度值为0101)，这时不使用任何选项。<br>3、区分服务（服务类型）<br>     占8位，在一般情况下都不使用这个字段。<br>4、总长度<br>     指报头和数据之和的长度，单位是字节。总长度字段为16位，故IP数据报的最大长度为65535。<br>     每一种数据链路层都有其自己的帧格式，其中包括帧格式中的数据字段的最大长度，这称为最大传送单元MTU。当IP数据报封装成链路层的帧时，此数据报的总长度不能超过对应MTU的值。若数据报长度超过对于MTU的值，就将数据报进行分片处理，此时数据报首部中的“总长度“字段是指分片后的每一个分片的报头长度和数据长度之和。<br>5、标识<br>     占16位。IP软件在存储器中维持一个计数器，每产生一个数据报，计数器就加1，并赋给标识字段。当数据报进行分片处理后，每个分片的标识值都与原数据报的标识值相同，则在接收端具有相同标识值的分片就能最终正确的重装成为原来的数据报。<br>6、标志<br>     占3位，但目前只有两位有意义。<br>     最低位记为MF。MF=1即表示后面”还有分片“的数据包。MF=0表示这已是若干数据包片中的最后一个。<br>     中间位记为DF，意思是”不能分片“。只有当DF=0时才允许分片。<br>7、片偏移<br>     占13位。表示每个数据报的分片在原数据报中的相对位置。片偏移以8个字节为偏移单位，即每个分片的长度一定是8字节的整数倍。<br>8、生存时间<br>     占8位。表示数据报在网络中的寿命。最初以秒为TTL值为单位，现在以跳数为单位，则目前的最大数据为255.<br>9、协议<br>     占8位，指出此数据报携带的数据是使用何种协议，以便使目的主机的IP层知道应将数据部分上交给那个处理过程。<br>     TCP对应协议字段值6；UDP对应协议字段值17<br>10、首部校验和<br>     占16位，该字段只校验数据报的报头，但不包括数据部分。<br>11、源地址<br>     占32位<br>12、目的地址<br>     占32位</p>
<h4 id="12-MTU的概念，啥叫路径MTU？-MTU发现机制，TraceRoute-了解-。"><a href="#12-MTU的概念，啥叫路径MTU？-MTU发现机制，TraceRoute-了解-。" class="headerlink" title="12. MTU的概念，啥叫路径MTU？ MTU发现机制，TraceRoute(了解)。"></a>12. MTU的概念，啥叫路径MTU？ MTU发现机制，TraceRoute(了解)。</h4><p>1、MTU的概念<br>MTU即Maximum Transmission Unit 最大传输单元。它是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位）。<br>2、路径MTU<br>路径MTU是指一条因特网传输路径中，从源地址到目的地址所经过的“路径”上的所有IP跳的最大传输单元的最小值。或者从另外一个角度来看，就是无需进行分片处理就能穿过这条“路径”的最大传输单元的最大值。<br>3、路径MTU的发现方法<br>这是确定两个IP主机之间路径最大传输单元的技术，其目的就是为了避免IP分片。首先源地址将数据报的DF位置位，在逐渐增大发送的数据报的大小——路径上任何需要将分组进行分片的设备都会将这种数据报丢弃并返回“数据报过大“的ICMP响应到源地址——这样源主机就”学习“到了无需分片就能通过这条路径的最大的最大传输单元。<br>4、TraceRoute<br>Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具。它的原理如下：它受到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包（每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签），而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器ip。<br>Traceroute提取发送 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。</p>
<h4 id="13-RIP协议的概念及算法。"><a href="#13-RIP协议的概念及算法。" class="headerlink" title="13. RIP协议的概念及算法。"></a>13. RIP协议的概念及算法。</h4><p>1、RIP协议的概念<br>     路由信息协议RIP是一种分布式的基于距离向量的路由选择协议属于内部网关协议。RIP协议中的“距离”也称为“跳数”，因为每经过一个路由器，跳数就加1。协议规定同一自治系统(A.S.)中的路由器每 30秒会与相邻的路由器交换子讯息，以动态的建立路由表。当传输数据时，RIP将选择一条具有最少路由器的路由。<br>2、算法<br>     对每一个相邻路由器发送过来的RIP报文，进行以下步骤：<br>（1）对地址为X的相邻路由器发来的RIP报文，先修改此报文中的所有项目：把“下一跳”字段中的地址都改为X，并把所有的”距离”字段的值加1.每个项目都有三个关键数据，即：目的网络N，距离是d，下一跳路由器是X。<br>（2）对修改后的RIP报文中的每一个项目，进行如下步骤：</p>
<ul>
<li>若原来的路由表中没有目的网络N，则把该项目添加到路由表中，</li>
<li>若下一跳路由器地址是X，则把收到的项目替换原路由表中的项目</li>
<li>若收到的项目中距离d小于路由表中的距离，则进行更新</li>
</ul>
<p>（3）若3分钟还没有收到相邻路由器的更新路由表，则把此相邻路由器记为不可到达的路由器，即把距离设置为16。<br>（4）返回</p>
<h4 id="14-ICMP协议的主要功能。"><a href="#14-ICMP协议的主要功能。" class="headerlink" title="14. ICMP协议的主要功能。"></a>14. ICMP协议的主要功能。</h4><p>它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用<br>侦测远端主机是否存在<br>建立及维护路由资料<br>重导数据传送路径<br>数据流量控制</p>
<h4 id="15-组播和多播的概念，IGMP的用途。"><a href="#15-组播和多播的概念，IGMP的用途。" class="headerlink" title="15. 组播和多播的概念，IGMP的用途。"></a>15. 组播和多播的概念，IGMP的用途。</h4><p><strong>组播</strong><br>主机之间的通讯模式，也就是加入了同一个组的主机可以接收到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯<br><strong>广播</strong><br>是指在IP子网内广播数据包，所有在子网内部的主机都将收到这些数据包。广播意味着网络向子网每一个主机都投递一份数据包，不论这些主机是否乐于接收该数据包。所以广播的使用范围非常小，只在本地子网内有效，通过路由器和网络设备控制广播传输。</p>
<p>组播协议与现在广泛使用的单播协议的不同之处在于，一个主机用单播协议向n个主机发送相同的数据时，发送主机需要分别向n个主机发送，共发送n次。一个主机用组播协议向n个主机发送相同的数据时，只要发送1次，其数据由网络中的路由器和交换机逐级进行复制并发送给各个接收方，这样既节省服务器资源也节省网络主干的带宽资源。</p>
<p><strong>IGMP（Internet Group Management Protocol）的用途</strong><br>它用来在ip主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。组播路由器不需要保存所有主机的成员关系，它只是通过igmp协议了解每个接口连接的网段上是否存在某个组播组的组成员。而主机只需要保存自己加入了哪些组播组。<br>简而言之，IGMP协议是让连接在本地局域网上的组播路由器知道本局域网上是否有主机上的某个进程参加或退出了某个组播组。<br><strong>环回地址/广播地址</strong><br>环回地址：127.0.0.1，通常被称为本地回环地址(Loop back address)，不属于任何一个有类别地址类。它代表设备的本地虚拟接口，所以默认被看作是永远不会宕掉的接口。<br>主要作用有两个：一是测试本机的网络配置，能PING通127.0.0.1说明本机的网卡和IP协议安装都没有问题；另一个作用是某些SERVER/CLIENT的应用程序在运行时需调用服务器上的资源，一般要指定SERVER的IP地址，但当该程序要在同一台机器上运行而没有别的SERVER时就可以把SERVER的资源装在本机，SERVER的IP地址设为127.0.0.1同样也可以运行。<br>广播地址：是专门用于同时向网络中所有工作站进行发送的一个地址。在使用TCP/IP 协议的网络中，主机标识段host ID 为全1 的IP 地址为广播地址，广播的分组传送给host ID段所涉及的所有计算机。<br> 例如，对于10.1.1.0 （255.255.255.0 ）网段，其广播地址为10.1.1.255 （255 即为2 进制的11111111 ），当发出一个目的地址为10.1.1.255 的分组（封包）时，它将被分发给该网段上的所有计算机。</p>
<h4 id="16-Ping协议的实现原理，ping-命令格式。"><a href="#16-Ping协议的实现原理，ping-命令格式。" class="headerlink" title="16. Ping协议的实现原理，ping 命令格式。"></a>16. Ping协议的实现原理，ping 命令格式。</h4><p>ping的原理是，向指定的IP地址发送一定长度的数据包，按照约定，若指定IP地址存在的话，会返回同样大小的数据包，当然，若在特定的时间内没有返回，就是“超时”，就认为指定的IP不存在。</p>
<h4 id="17-子网划分的概念，子网掩码。"><a href="#17-子网划分的概念，子网掩码。" class="headerlink" title="17. 子网划分的概念，子网掩码。"></a>17. 子网划分的概念，子网掩码。</h4><p>1、子网划分的概念<br>一个拥有许多物理网络的单位，可将所属的物理网络划分为若干个子网。划分子网纯属一个单位内部的事情。本单位以外的网络看不见这个网络是由多少子网组成，因为这个单位对外仍然表现一个网络。<br>划分子网的方法是从网络的主机号借用若干位作为子网号subnet-id。于是两级IP地址在本单位内部就变为三级IP地址：网络号，子网号和主机号。<br>凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据IP数据报的目的网络号找到连接在本单位网络上的路由器。但此路由器在收到IP数据报后，在按目的网络号和子网号找到目的子网，把IP数据报交付给目的主机<br>2、子网掩码<br>子网掩码也是32位，由一串1和跟随的一串0组成。子网掩码中的1对应于IP地址中原来的网络号和子网号，而子网掩码中的0对应于现在的主机号。<br>故将子网掩码和IP地址进行按位”与“运算（AND），就可得出网络地址。<br>划分子网增加了 灵活性，但也减少了能够连接在网络上主机总数。</p>
<h4 id="18-IP地址的分类，如何划分的，及会计算各类地址支持的主机数。"><a href="#18-IP地址的分类，如何划分的，及会计算各类地址支持的主机数。" class="headerlink" title="18. IP地址的分类，如何划分的，及会计算各类地址支持的主机数。"></a>18. IP地址的分类，如何划分的，及会计算各类地址支持的主机数。</h4><p>A类<br>1.0.0.0 到126.0.0.0<br>0.0.0.0 和127.0.0.0保留<br>B<br>128.1.0.0到191.254.0.0<br>128.0.0.0和191.255.0.0保留<br>C<br>192.0.1.0 到223.255.254.0<br>192.0.0.0和223.255.255.0保留<br>D<br>224.0.0.0到239.255.255.255用于多点广播<br>E<br>240.0.0.0到255.255.255.254保留<br>255.255.255.255用于广播</p>
<h4 id="19-DNS的概念，用途，DNS查询的实现算法。"><a href="#19-DNS的概念，用途，DNS查询的实现算法。" class="headerlink" title="19. DNS的概念，用途，DNS查询的实现算法。"></a>19. DNS的概念，用途，DNS查询的实现算法。</h4><p>1、DNS的概念，用途<br>DNS是由解析器以及域名服务器组成的。域名服务器是指保存有该网络中所有主机的域名和对应IP地址，并具有将域名转换为IP地址功能的服务器。DNS使用TCP与UDP端口号都是53，主要使用UDP，服务器之间备份使用TCP。<br>域名到IP地址的解析过程的要点如下：当某一个应用进程需要主机名解析为IP地址时，该应用进程就调用解析程序，并成为DNS的一个客户，把待解析的域名放在DNS请求报文中，以UDP用户数据报方式发给本地域名服务器。本地域名服务器在查找域名后，把对应的IP地址放在回答报文中返回。应用进程获得目的主机的IP地址后即可进行通信。<br>若本地域名服务器不能回答该请求，则此域名服务器就暂时成为DNS中的另一个客户，并向其他域名服务器发出查询请求。这种过程直至找到能够回答该请求的域名服务器为止。<br>2、DNS查询算法<br>主机向本地域名服务器的查询一般都是采用递归查询，即如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步的查询。因此，递归查询返回的查询结果或是所要查询的IP地址，或是报错。<br>本地域名服务器想根服务器的查询通常采用迭代查询，即当根域名服务器收到本地域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器“下一次应向那个域名服务器进行查询”。然后让本地域名服务器进行后续的查询。根域名服务器通常把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪一个权限域名服务器进行查询。本地域名服务器就这样进行迭代查询。</p>
<ol>
<li>TCP与UDP的概念，相互的区别及优劣。<br>1 、TCP（Transmission Control Protocol）的概念<br>TCP是一种面向连接的，提供可靠交付服务和全双工通信的，基于字节流的端到端的传输层通信协议。<br>TCP在传输数据之前必须先建立连接，数据传输结束后要释放连接。<br>每一条TCP连接只能有2个端点，故TCP不提供广播或多播服务。<br>TCP提供可靠交付，通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。<br>TCP是面向字节流的。虽然应用进程和TCP的交互是一次一个数据块(大小不等），但TCP把英语程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP并不知道所传输的字节流的含义。<br>2、UDP（User Datagram Protocol）的概念<br>UDP是一种无连接的，尽最大努力交付的，基于报文的端到端的传输层通信协议。<br>UDP，在发送数据之前不需要建立连接<br>UDP不保证可靠交付，主机不需要位置复杂的连接状态<br>UDP是面向报文的。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的的边界，即应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。在接收端，UDP一次交付一个完整的报文。<br>UDP没有拥塞控制，网络出现的拥塞不会使源主机的发送速率降低。<br>UDP支持一对一、一对多、多对一和多对多的交互通信。<br>UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。<br>3、区别<br>TCP协议面向连接，UDP协议面向非连接<br>TCP协议传输速度慢，UDP协议传输速度快<br>TCP协议保证数据顺序，UDP协议不保证<br>TCP协议保证数据正确性，UDP协议可能丢包<br>TCP协议对系统资源要求多，UDP协议要求少<br>4、使用情况<br>TCP协议适用于对效率要求相对低，但对准确性要求相对高的场景下，或者是有一种连接概念的场景下；而UDP协议适用于对效率要求相对高，对准确性要求相对低的场景。<h4 id="21-UDP报文的格式，字段的意义。"><a href="#21-UDP报文的格式，字段的意义。" class="headerlink" title="21. UDP报文的格式，字段的意义。"></a>21. UDP报文的格式，字段的意义。</h4>首部字段很简单，只有8个字节，由4个字段组成，每个字段的长度都是两个字节。<br>1）源端口：源端口号。在需要对方回信时选用。不需要时可用全0。<br>2）目的端口：目的端口号。这在终点交付报文时必须要使用到。<br>3）长度： UDP用户数据报的长度，其最小值是8（仅有首部）。<br>4）校验和：检测UDP用户数据报在传输中是否有错。有错就丢弃。</li>
</ol>
<h4 id="22-TCP报文的格式，字段的意义。"><a href="#22-TCP报文的格式，字段的意义。" class="headerlink" title="22. TCP报文的格式，字段的意义。"></a>22. TCP报文的格式，字段的意义。</h4><p><strong>源端口和目的端口</strong> ：各占2个字节，分别写入源端口号和目的端口号。<br><strong>序号</strong> ：占4个字节。序号使用mod运算。TCP是面向字节流的，在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。故该字段也叫做“报文段序号”。<br><strong>确认序号</strong> ：占4个字节，是期望收到对方下一个报文段的第一个数据字节的序号。若确认序号=N,则表明：到序号N-1为止的所有数据都已正确收到。<br><strong>数据偏移</strong> ：占4位，表示TCP报文段的首部长度。注意，“数据偏移”的单位是32位字（即以4字节长的字为计算单位）。故TCP首部的最大长度为60字节。<br><strong>保留</strong> ：占6位，保留为今后使用，目前置为0；<br><strong>紧急URG</strong> ：当URG=1，表明紧急指针字段有效。这时发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。<br><strong>确认ACK</strong> ：当ACK=1时，确认字段才有效。当ACK=0时，确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1。<br><strong>推送PSH</strong> ：接收方TCP收到PSH=1的报文段，就尽快地交付给接收应用进程，而不再等到整个缓存都填满了后再向上交付。<br><strong>复位RST</strong> ：当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立运输连接。<br><strong>同步SYN</strong> ：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1。故SYN置为1，就表示这是一个连接请求和连接接收报文。<br><strong>终止FIN</strong> ：用来释放连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。<br><strong>窗口</strong> ：占2个字节。窗口值作为接收方让发送方设置其发送窗口的依据。<br><strong>检验和</strong> ：占2字节。检验和字段检验的范围包括首部和数据这两部分。和UDP数据报一样，在计算检验和时，也要在TCP报文段的前面加上12字节的伪首部。伪首部的格式与UDP用户数据报的伪首部一样，但要将伪首部第四个字段中的17 改为6（协议号），把第5字段中的UDP长度改为TCP长度。<br><strong>紧急指针</strong> ：占2字节。紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据的字节数。</p>
<ol>
<li><a href="http://www.cnblogs.com/deliver/p/5471231.html" target="_blank" rel="external">TCP通过哪些措施，保证传输可靠？</a><br>1、确认和重传：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就重传。<br>2、数据校验<br>3、数据合理分片和排序：<br>　　UDP：IP数据报大于1500字节,大于MTU.这个时候发送方IP层就需要分片(fragmentation).把数据报分成若干片,使每一片都小于MTU.而接收方IP层则需要进行数据报的重组.这样就会多做许多事情,而更严重的是,由于UDP的特性,当某一片数据传送中丢失时,接收方便无法重组数据报.将导致丢弃整个UDP数据报.<br>　　tcp会按MTU合理分片，接收方会缓存未按序到达的数据，重新排序后再交给应用层。<br>4、流量控制：当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。<br>5、拥塞控制：当网络拥塞时，减少数据的发送。<h4 id="24-三次握手，四次断开过程。"><a href="#24-三次握手，四次断开过程。" class="headerlink" title="24. 三次握手，四次断开过程。"></a>24. 三次握手，四次断开过程。</h4><strong>三次握手：</strong><br><em>第一次握手：</em> 客户端发送syn包(syn=x)到服务器，并进入SYN_SEND状态，等待服务器确认；<br><em>第二次握手：</em> 服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；<br><em>第三次握手：</em> 客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。<br>握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。<br><strong>四次挥手:</strong><br>与建立连接的“三次握手”类似，断开一个TCP连接则需要“四次握手”。<br><em>第一次挥手：</em> 主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不 会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可 以接受数据。<br><em>第二次挥手：</em> 被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）。<br><em>第三次挥手：</em> 被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。<br><em>第四次挥手：</em> 主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。<br><a href="http://images0.cnblogs.com/blog2015/621032/201508/092017231747399.jpg" target="_blank" rel="external">http://images0.cnblogs.com/blog2015/621032/201508/092017231747399.jpg</a></li>
</ol>
<h4 id="25-TIME-WAIT状态的概念及意义。"><a href="#25-TIME-WAIT状态的概念及意义。" class="headerlink" title="25. TIME_WAIT状态的概念及意义。"></a>25. TIME_WAIT状态的概念及意义。</h4><p>1）可靠地实现TCP全双工连接的终止<br>    在进行关闭连接四路握手协议时，最后的ACK是由主动关闭端发出的，如果这个最终的ACK丢失，服务器将重发最终的FIN，因此客户端必须维护状态信息允 许它重发最终的ACK。如果不维持这个状态信息，那么客户端将响应RST分节，服务器将此分节解释成一个错误（在java中会抛出connection reset的SocketException)。因而，要实现TCP全双工连接的正常终止，必须处理终止序列四个分节中任何一个分节的丢失情况，主动关闭 的客户端必须维持状态信息进入TIME_WAIT状态。<br>2）允许老的重复分节在网络中消逝<br>    TCP分节可能由于路由器异常而“迷途”，在迷途期间，TCP发送端可能因确认超时而重发这个分节，迷途的分节在路由器修复后也会被送到最终目的地，这个 原来的迷途分节就称为lost duplicate。在关闭一个TCP连接后，马上又重新建立起一个相同的IP地址和端口之间的TCP连接，后一个连接被称为前一个连接的化身 （incarnation)，那么有可能出现这种情况，前一个连接的迷途重复分组在前一个连接终止后出现，从而被误解成从属于新的化身。为了避免这个情 况，TCP不允许处于TIME_WAIT状态的连接启动一个新的化身，因为TIME_WAIT状态持续2MSL，就可以保证当成功建立一个TCP连接的时 候，来自连接先前化身的重复分组已经在网络中消逝。</p>
<h4 id="26-滑动窗口协议与停止等待协议的区别。"><a href="#26-滑动窗口协议与停止等待协议的区别。" class="headerlink" title="26. 滑动窗口协议与停止等待协议的区别。"></a>26. 滑动窗口协议与停止等待协议的区别。</h4><p>滑动窗口协议中，允许发送方发送多个分组（当有多个分组可用时）而不需等待确认，但它受限于在流水线 中为未确认的分组数不能超过某个最大允许数N。滑动窗口协议是TCP使用的一种流量控制方法，此协议能够加速数据的传输。 只有在接收窗口向前滑动时（与此同时也发送了确认），发送窗口才有可能向前滑动。<br>收发两端的窗口按照以上规律不断地向前滑动，因此这种协议称为滑动窗口协议。<br>当发送窗口和接收窗口的大小都等于1时，就是停止等待协议。<br>停止等待协议是tcp保证传输可靠的重要途径,”停止等待”就是指发送完一个分组就停止发送,等待对方的确认,只有对方确认过,才发送下一个分组.</p>
<h4 id="27-TCP的流量控制和拥塞控制实现原理-会画拥塞控制的典型图-。"><a href="#27-TCP的流量控制和拥塞控制实现原理-会画拥塞控制的典型图-。" class="headerlink" title="27. TCP的流量控制和拥塞控制实现原理(会画拥塞控制的典型图)。"></a>27. <a href="http://blog.csdn.net/liuchen1206/article/details/8599542" target="_blank" rel="external">TCP的流量控制和拥塞控制实现原理</a>(会画拥塞控制的典型图)。</h4><h4 id="28-TCP的快速重传与快速恢复算法。"><a href="#28-TCP的快速重传与快速恢复算法。" class="headerlink" title="28. TCP的快速重传与快速恢复算法。"></a>28. TCP的快速重传与快速恢复算法。</h4><p><strong>快速重传：</strong><br>当TCP接收端收到一个失序的报文时，会立即产生一个ACK（一个重复的ack，即并不是对这个失序报文的确认，而是上一个已确认的报文的ACK），这个ack不应该被延迟。这个ack的目的是让发送方知道接收方真正希望接收的报文。<br>也正是因为上述的这种ack，从而我们不能确认一个重复的ack是因为什么原因发送的，是一个报文丢失了，还是一个对方收到了一个失序的报文产生的。因此在TCP发送端的处理是会等待少量的ack到来，通常认为失序产生的ack一般不会超过两个（这里失序的情况有可能是同一个失序报文在网络中存在多个拷贝，如果是这种理解的话应该是不大可能超过2个，因为多个相同的拷贝到达同一个目的网络，这说明网络拓扑可能本身存在了问题，存在多条不同的代价的路径而不是只优选最优路径。当然这里也可能是多个不同的失序报文，这样的话就完全有可能超过2个，但是这种大部分的可能就是有某个报文被丢失了，这里就需要重传）。如果在一个RTT时间段中接收到了3个或者3个以上的ack，那么这就刚括号中分析的那样，很可能就是某个报文丢失了。<br>对于这种报文丢失的情况可以有两种方案进行选择：<br>1.在RTT时间到期时进行慢启动，遵循拥塞避免算法中的慢启动情形。<br>2.不等待RTT时间到期，直接重传丢失的数据。这就是快速重传的机制。<br>这里TCP为什么选择快速重传：<br>主要是因为发送方一直都有收到对端的ack，这个说明网络质量是好的，至少并没有明显的拥塞发生，因为对端能够发送ack是因为收到了一个报文，即说明网络是相对畅通的，它能够一个一个的收到报文发送出ack。所以并不需要采用慢启动来降低网络利用率。<br>快速恢复算法来解决：</p>
<ol>
<li>当收到第三个ack时，将ssthresh设置成当前cwnd的一半，设置cwnd为ssthresh＋接受的ack个数＊MSS，发送重传的数据报。</li>
<li>在没有收到新数据的ack之前，每收到一个重复的ack，cwnd就增加1个报文段。并在允许的情况下发送一个报文段（这里的允许条件是cwnd的大小要大于未被确认的报文大小）。</li>
<li>当收到了新数据的ack时，设置cwnd为ssthresh的值（为发生重传时窗口的一半）。这个时候后续就开始了拥塞避免算法，因为cwnd &gt;= ssthresh，所以并不是拥塞中的慢启动。</li>
</ol>
<h4 id="29-TFTP与FTP的区别。"><a href="#29-TFTP与FTP的区别。" class="headerlink" title="29. TFTP与FTP的区别。"></a>29. TFTP与FTP的区别。</h4><p>文件传输协议(FTP)实际上就是传输文件的协议,它可以应用在任意两台主机之间，但是FTP不仅仅是一个协议,它同时也是一个程序。作为协议,FTP是被应用程序所使用的;而作为程序,用户需要通过手动方式来使用FTP并完成文件的传送。FTP允许执行对目录和文件的访问,并且可以完成特定类型的目录操作,例如将文件重新定位到不同的目录中。显然,FTP是与Telnet合作一同来完成对FTP服务器的登录操作,并在这之后再开始提供文件传送服务的。<br>然而,通过FTP访问主机这只是第一步。随后,用户必须通过一个由系统管理员为保护系统资源而设置的安全登录认证,这个认证需要输人正确的口令和用户名。但是,也可以通过使用用户名“anonymous” 来尝试登录,当然,通过这种方式完成登录后,所能访问的内容将会受到某些限制。即使FTP可以被用户以应用程序的方式来使用,FTP的功能也只限于列表和目录操作、文件内容输人,以及在主机间进行文件拷贝。它不能远程执行程序文件。<br>简单文件传输协议(TFTP)是FTP的简化版本,只有在你确切地知道想要得到的义件名及它的准确位置时,才可有选择地使用TFTP。TFTP是一个非常易用的、快捷的程序!TFTP并不提供像FTP那样的强大功能。TFTP不提供目录浏览的功能，它只能完成文件的发送和接收操作。这个紧凑的小协议在传送的数据单元上也是节省的,它发送比FTP更小的数据块,同时它也没有FTP所需要的传送确认,因而它是不可靠的。正是由于这个内在的安全风险,事实上只有很少的站点支持TFTP服务<br>FTP 是完整、 面向会话、常规用途文件传输协议。而 TFTP 用作 bones bare - 特殊目的文件传输协议。<br>交互使用 FTP。 TFTP 允许仅单向传输的文件。<br>FTP 提供身份验证。而TFTP 不。<br>FTP 使用已知 TCP 端口号： 20 的数据和 21 用于连接对话框。 TFTP 用于 UDP 端口号 69 其文件传输活动。<br>因为 TFTP 不支持验证 WindowsNT ，所以FTP 服务器服务不支持 TFTP。<br>FTP 依赖于 TCP，是面向连接并提供可靠的控件。 TFTP 依赖 UDP， 需要减少开销, 几乎不提供控件。</p>
<h4 id="30-阻塞方式和非阻塞方式，阻塞connect与非阻塞connect。-比较难，有兴趣可以了解"><a href="#30-阻塞方式和非阻塞方式，阻塞connect与非阻塞connect。-比较难，有兴趣可以了解" class="headerlink" title="30. 阻塞方式和非阻塞方式，阻塞connect与非阻塞connect。(比较难，有兴趣可以了解)"></a>30. 阻塞方式和非阻塞方式，阻塞connect与非阻塞connect。(比较难，有兴趣可以了解)</h4><h4 id="31-HTTP基本格式。（java程序员必须掌握）"><a href="#31-HTTP基本格式。（java程序员必须掌握）" class="headerlink" title="31. HTTP基本格式。（java程序员必须掌握）"></a>31. HTTP基本格式。（java程序员必须掌握）</h4><p><a href="http://blog.csdn.net/hudashi/article/details/50789006" target="_blank" rel="external">http://blog.csdn.net/hudashi/article/details/50789006</a><br><a href="http://www.xuebuyuan.com/1599560.html" target="_blank" rel="external">http://www.xuebuyuan.com/1599560.html</a></p>
<hr>
<h1 id="三：设计模式"><a href="#三：设计模式" class="headerlink" title="三：设计模式"></a>三：设计模式</h1><h4 id="1-各种常用模式的用途，使用方法。"><a href="#1-各种常用模式的用途，使用方法。" class="headerlink" title="1. 各种常用模式的用途，使用方法。"></a>1. 各种常用模式的用途，使用方法。</h4><h4 id="2-单例模式的双重检查实现。"><a href="#2-单例模式的双重检查实现。" class="headerlink" title="2. 单例模式的双重检查实现。"></a>2. 单例模式的双重检查实现。</h4><p>第一种（懒汉，线程不安全）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">public class Singleton &#123;  </div><div class="line">     private static Singleton instance;  </div><div class="line">      private Singleton ()&#123;&#125;   </div><div class="line">      public static Singleton getInstance() &#123;  </div><div class="line">      if (instance == null) &#123;  </div><div class="line">          instance = new Singleton();  </div><div class="line">      &#125;  </div><div class="line">     return instance;  </div><div class="line">     &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种写法lazy loading很明显，但是致命的是在多线程不能正常工作。</p>
<p>第二种（懒汉，线程安全）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">public class Singleton &#123;       </div><div class="line">  private static Singleton instance;  </div><div class="line">     private Singleton ()&#123;&#125;</div><div class="line">     public static synchronized Singleton getInstance() &#123;  </div><div class="line">     if (instance == null) &#123;  </div><div class="line">         instance = new Singleton();  </div><div class="line">     &#125;  </div><div class="line">     return instance;  </div><div class="line">     &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种写法能够在多线程中很好的工作，而且看起来它也具备很好的lazy loading，但是，遗憾的是，效率很低，99%情况下不需要同步。</p>
<p>第三种（饿汉）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">public class Singleton &#123;  </div><div class="line">   private static Singleton instance = new Singleton();  </div><div class="line">   private Singleton ()&#123;&#125;</div><div class="line">   public static Singleton getInstance() &#123;  </div><div class="line">   return instance;  </div><div class="line">   &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用getInstance方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到lazy loading的效果。</p>
<p>第四种（饿汉，变种）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"> public class Singleton &#123;  </div><div class="line">     private Singleton instance = null;  </div><div class="line">     static &#123;  </div><div class="line">     instance = new Singleton();  </div><div class="line">     &#125;  </div><div class="line">     private Singleton ()&#123;&#125;</div><div class="line">     public static Singleton getInstance() &#123;  </div><div class="line">     return this.instance;  </div><div class="line">     &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>表面上看起来差别挺大，其实更第三种方式差不多，都是在类初始化即实例化instance。</p>
<p>第五种（静态内部类）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">public class Singleton &#123;  </div><div class="line">    private static class SingletonHolder &#123;  </div><div class="line">    private static final Singleton INSTANCE = new Singleton();  </div><div class="line">    &#125;  </div><div class="line">    private Singleton ()&#123;&#125;</div><div class="line">    public static final Singleton getInstance() &#123;  </div><div class="line">        return SingletonHolder.INSTANCE;  </div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第三种和第四种方式不同的是（很细微的差别）：第三种和第四种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三和第四种方式就显得很合理。</p>
<p>第六种（枚举）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">public enum Singleton &#123;  </div><div class="line">   INSTANCE;  </div><div class="line">   public void whateverMethod() &#123;  </div><div class="line">   &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种方式是Effective Java作者Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象，可谓是很坚强的壁垒啊，不过，个人认为由于1.5中才加入enum特性，用这种方式写不免让人感觉生疏，在实际工作中，我也很少看见有人这么写过。</p>
<p>第七种（双重校验锁）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">public class Singleton &#123;  </div><div class="line">   private volatile static Singleton singleton;  </div><div class="line">   private Singleton ()&#123;&#125;   </div><div class="line">   public static Singleton getSingleton() &#123;  </div><div class="line">    if (singleton == null) &#123;  </div><div class="line">       synchronized (Singleton.class) &#123;  </div><div class="line">       if (singleton == null) &#123;  </div><div class="line">           singleton = new Singleton();  </div><div class="line">       &#125;  </div><div class="line">      &#125;  </div><div class="line">    &#125;  </div><div class="line">    return singleton;  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="3-MVC模式"><a href="#3-MVC模式" class="headerlink" title="3. MVC模式"></a>3. MVC模式</h4><p>MVC 是一种使用 MVC（Model View Controller 模型-视图-控制器）设计创建 Web 应用程序的模式：[1]<br>Model（模型）表示应用程序核心（比如数据库记录列表）。<br>View（视图）显示数据（数据库记录）。<br>Controller（控制器）处理输入（写入数据库记录）。<br>MVC 模式同时提供了对 HTML、CSS 和 JavaScript 的完全控制。<br>Model（模型）是应用程序中用于处理应用程序数据逻辑的部分。<br>　　通常模型对象负责在数据库中存取数据。<br>View（视图）是应用程序中处理数据显示的部分。<br>　　通常视图是依据模型数据创建的。<br>Controller（控制器）是应用程序中处理用户交互的部分。<br>　　通常控制器负责从视图读取数据，控制用户输入，并向模型发送数据。<br>MVC 分层有助于管理复杂的应用程序，因为您可以在一个时间内专门关注一个方面。例如，您可以在不依赖业务逻辑的情况下专注于视图设计。同时也让应用程序的测试更加容易。<br>MVC 分层同时也简化了分组开发。不同的开发人员可同时开发视图、控制器逻辑和业务逻辑。</p>
<h1 id="算法、数据结构"><a href="#算法、数据结构" class="headerlink" title="算法、数据结构"></a>算法、数据结构</h1><h2 id="一：算法"><a href="#一：算法" class="headerlink" title="一：算法"></a>一：算法</h2><ol>
<li>算法的几个特征是什么。</li>
<li>算法复杂性的定义。大O、θ、Ω、小o分别表示的含义。</li>
<li>递归算法的定义、递归算法的两要素。</li>
<li>分治算法的思想，经典的分治算法(全排列、二分搜索、归并排序、快速排序、线性时间选择、最接近点对问题)。</li>
<li>动态规划算法解题框架，动态规划算法的两个要素是什么？备忘录方法是什么？</li>
<li>经典的动态规划问题(矩阵连乘问题、最长公共子序列问题、0-1背包问题)。</li>
<li>贪心算法的思想，贪心算法的两个要素。</li>
<li>经典的贪心问题(活动安排问题、背包问题、装载问题、哈夫曼编码、单源最短路径、最小生成树问题)。</li>
<li>回溯法的思想，回溯法中有哪两种典型的模型。</li>
<li>经典的回溯算法(n后问题、0-1背包问题、旅行售货商问题)。</li>
<li>分支限界法思想，有哪两种分支限界法。</li>
<li>经典的分支限界算法(0-1背包问题、旅行售货商问题)。</li>
</ol>
<h2 id="二：数据结构"><a href="#二：数据结构" class="headerlink" title="二：数据结构"></a>二：数据结构</h2><ol>
<li>数据结构的定义。</li>
<li>栈的两个应用：括号匹配和表达式的计算。是怎么应用的？表达式计算用的是哪种表达方式？有什么好处?</li>
<li>字符串匹配算法：朴素的匹配算法、KMP算法。</li>
<li>二叉树前序、中序、后序递归遍历算法。二叉树前序非递归遍历算法。</li>
<li>堆，建堆算法，堆的插入和删除算法，堆排序。</li>
<li>哈希。哈希函数的有哪些种？余数的取法？ 处理冲突的方法？ 闭散列方法有哪些？</li>
<li>二叉搜索树的搜索、插入、删除。时间复杂度。</li>
<li>二叉平衡树的插入结点的原理，有哪几种旋转方式？分别适用于哪种情况。分析二叉平衡树的时间复杂度。</li>
<li>红黑树的定义，红黑树的性能分析和与二叉平衡树的比较。</li>
<li>图有哪些储存表示。</li>
<li>链表插入排序、链表归并排序。</li>
<li>常见的有哪几种排序算法，试比较其时间复杂度，以及是否稳定，及各自使用的情形。</li>
<li>常用分配排序有哪几种？ 基数排序的定义，分类及原理。</li>
<li>B树、B+树、Trie的概念及用途，添加删除结点的原理。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/13/面试基础题/" data-id="citkups29000bsna4jk0vy1ob" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/面试/">面试</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/09/12/自我相关/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">自我相关</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hello/">Hello</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试/">面试</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hello/" style="font-size: 10px;">Hello</a> <a href="/tags/面试/" style="font-size: 20px;">面试</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/09/13/面试基础题/">面试基础题</a>
          </li>
        
          <li>
            <a href="/2016/09/12/自我相关/">自我相关</a>
          </li>
        
          <li>
            <a href="/2016/09/12/180家公司网申地址/">180家公司网申地址</a>
          </li>
        
          <li>
            <a href="/2016/09/07/搭建Hexo-Github的个人博客/">搭建Hexo+Github的个人博客</a>
          </li>
        
          <li>
            <a href="/2016/09/07/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Huagui Ren<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>